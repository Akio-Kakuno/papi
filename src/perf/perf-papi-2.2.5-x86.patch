diff -crN linux-2.2.5/Documentation/Configure.help linux-2.2.5-perf/Documentation/Configure.help
*** linux-2.2.5/Documentation/Configure.help	Wed Jun  2 08:36:15 1999
--- linux-2.2.5-perf/Documentation/Configure.help	Sun Jul 18 19:45:41 1999
***************
*** 1642,1647 ****
--- 1642,1656 ----
  
    If you don't know what to do, choose "386".
  
+ CPU Performance Counter Support
+ CONFIG_PERF
+   This provides support (via a syscall) for hardware performance counters
+   present in the Pentium (untested), Pentium Pro and Pentium II. This patch
+   is a modification to that originally written by Erik Hendriks for the
+   Beowulf project at http://www.beowulf.org/software/software.html. This patch
+   is intended to provide some bug fixes and support for PAPI. See
+   http://icl.cs.utk.edu/projects/papi for further details. (mucci@cs.utk.edu)
+ 
  VGA text console
  CONFIG_VGA_CONSOLE
    Saying Y here will allow you to use Linux in text mode through a
diff -crN linux-2.2.5/arch/i386/config.in linux-2.2.5-perf/arch/i386/config.in
*** linux-2.2.5/arch/i386/config.in	Fri Mar 12 20:39:50 1999
--- linux-2.2.5-perf/arch/i386/config.in	Sun Jul 18 19:45:41 1999
***************
*** 36,41 ****
--- 36,46 ----
  bool 'Math emulation' CONFIG_MATH_EMULATION
  bool 'MTRR (Memory Type Range Register) support' CONFIG_MTRR
  bool 'Symmetric multi-processing support' CONFIG_SMP
+ 
+ if [ "$CONFIG_M686" = "y" ]; then
+   bool 'CPU Performance Counter Support' CONFIG_PERF
+ fi
+ 
  endmenu
  
  mainmenu_option next_comment
diff -crN linux-2.2.5/arch/i386/kernel/Makefile linux-2.2.5-perf/arch/i386/kernel/Makefile
*** linux-2.2.5/arch/i386/kernel/Makefile	Wed Jan 20 13:18:53 1999
--- linux-2.2.5-perf/arch/i386/kernel/Makefile	Sun Jul 18 19:45:41 1999
***************
*** 50,55 ****
--- 50,59 ----
  O_OBJS += visws_apic.o
  endif
  
+ ifdef CONFIG_PERF
+ O_OBJS += perf.o
+ endif
+ 
  head.o: head.S $(TOPDIR)/include/linux/tasks.h
  	$(CC) -D__ASSEMBLY__ $(AFLAGS) -traditional -c $*.S -o $*.o
  
diff -crN linux-2.2.5/arch/i386/kernel/entry.S linux-2.2.5-perf/arch/i386/kernel/entry.S
*** linux-2.2.5/arch/i386/kernel/entry.S	Wed Jan 20 14:05:59 1999
--- linux-2.2.5-perf/arch/i386/kernel/entry.S	Sun Jul 18 19:45:41 1999
***************
*** 40,45 ****
--- 40,46 ----
   * "current" is in register %ebx during any slow entries.
   */
  
+ #include <linux/config.h>
  #include <linux/sys.h>
  #include <linux/linkage.h>
  #include <asm/segment.h>
***************
*** 560,565 ****
--- 561,572 ----
  	.long SYMBOL_NAME(sys_ni_syscall)		/* streams1 */
  	.long SYMBOL_NAME(sys_ni_syscall)		/* streams2 */
  	.long SYMBOL_NAME(sys_vfork)            /* 190 */
+ #ifdef CONFIG_PERF
+ 	.rept NR_syscalls-190-5
+ 		.long SYMBOL_NAME(sys_ni_syscall)
+ 	.long SYMBOL_NAME(sys_perf)		/* 252 */
+ 	.endr
+ #endif
  
  	/*
  	 * NOTE!! This doesn't have to be exact - we just have
***************
*** 567,572 ****
--- 574,585 ----
  	 * entries. Don't panic if you notice that this hasn't
  	 * been shrunk every time we add a new system call.
  	 */
+ #ifdef CONFIG_PERF
+ 	.rept NR_syscalls-252
+ 		.long SYMBOL_NAME(sys_ni_syscall)
+ 	.endr
+ #else
  	.rept NR_syscalls-190
  		.long SYMBOL_NAME(sys_ni_syscall)
  	.endr
+ #endif
diff -crN linux-2.2.5/arch/i386/kernel/irq.c linux-2.2.5-perf/arch/i386/kernel/irq.c
*** linux-2.2.5/arch/i386/kernel/irq.c	Wed Jun  2 08:36:15 1999
--- linux-2.2.5-perf/arch/i386/kernel/irq.c	Sun Jul 18 19:45:41 1999
***************
*** 321,326 ****
--- 321,329 ----
  BUILD_SMP_INTERRUPT(invalidate_interrupt)
  BUILD_SMP_INTERRUPT(stop_cpu_interrupt)
  BUILD_SMP_INTERRUPT(mtrr_interrupt)
+ #ifdef CONFIG_PERF
+ BUILD_SMP_INTERRUPT(perf_sys_update_interrupt)
+ #endif
  BUILD_SMP_INTERRUPT(spurious_interrupt)
  
  /*
***************
*** 1083,1088 ****
--- 1086,1096 ----
  
  	/* IPI for MTRR control */
  	set_intr_gate(MTRR_CHANGE_VECTOR, mtrr_interrupt);
+ 
+ #ifdef CONFIG_PERF
+ 	/* IPI for perf counter update */
+ 	set_intr_gate(PERF_SYS_UPDATE_VECTOR,perf_sys_update_interrupt);
+ #endif
  
  	/* IPI vector for APIC spurious interrupts */
  	set_intr_gate(SPURIOUS_APIC_VECTOR, spurious_interrupt);
diff -crN linux-2.2.5/arch/i386/kernel/irq.h linux-2.2.5-perf/arch/i386/kernel/irq.h
*** linux-2.2.5/arch/i386/kernel/irq.h	Wed Jun  2 08:46:35 1999
--- linux-2.2.5-perf/arch/i386/kernel/irq.h	Sun Jul 18 19:45:41 1999
***************
*** 71,76 ****
--- 71,78 ----
   */
  #define IRQ0_TRAP_VECTOR	0x51
  
+ #define PERF_SYS_UPDATE_VECTOR	0x52
+ 
  /*
   * This IRQ should never happen, but we print a message nevertheless.
   */
diff -crN linux-2.2.5/arch/i386/kernel/perf.c linux-2.2.5-perf/arch/i386/kernel/perf.c
*** linux-2.2.5/arch/i386/kernel/perf.c	Wed Dec 31 19:00:00 1969
--- linux-2.2.5-perf/arch/i386/kernel/perf.c	Wed Jul 21 02:56:19 1999
***************
*** 0 ****
--- 1,387 ----
+ /* Modified by Philip J. Mucci. mucci@cs.utk.edu (Feb-July 1999)
+    for PAPI. http://icl.cs.utk.edu/projects/papi
+ 
+    Major Modifications:
+    
+    This kernel externsion now supports a third counter. Counter 2 is
+    a software only, per process cycle counter. 
+    It counts WALL clock cycles. Counting domain settings
+    have no effect on it. To turn it on, write a 1 to configuration register
+    2 in either a call to PERF_FASTCONFIG or PERF_SET_CONFIG.
+ 
+    Added calls:
+ 
+    PERF_SYS_RESET_COUNTERS: 
+    	- Resets the values of the counters without changing configuration
+ 	registers.
+    PERF_RESET_COUNTERS: 
+    	- Resets the values of the counters without changing configuration
+ 	registers.
+    PERF_FASTCONFIG:
+    	- Configuration register transfer. 1st arg is a pointer
+ 	to an array of 3 unsigned int's. We don't need to PERF_ENABLE
+ 	if you set the proper bits on counter 0. This saves 1000's of 
+ 	cycles.
+    PERF_FASTREAD:
+    	- Read the array of 3 unsigned long long's from the scheduler
+ 	structure into arg1. This saves 1000's of cycles.
+    PERF_FASTWRITE:
+    	- Write the array of 3 unsigned long long's to the scheduler
+ 	structure from arg1. This saves 1000's of cycles.
+    PERF_GET_OPT:
+    PERF_SET_OPT:
+    
+    Added options:
+ 
+    PERF_SUM_CPUS
+    	- To return cumulative counts when using the SYS interface.
+    PERF_DO_CHILDREN
+    	- Child processes/threads inherit the counting hardware setting
+ 	and lock the use of their interface. When the parent calls wait()
+ 	the values are automatically added to those in the parent. 
+ */
+ 
+ /*
+  * Pentium Pro hardware performance counter support
+  *
+  * Erik Hendriks <hendriks@cesdis.gsfc.nasa.gov>
+  * (Feb 12 1998)
+  */
+ #include <linux/kernel.h>
+ #include <linux/sched.h>
+ #include <linux/mm.h>
+ #include <linux/errno.h>
+ #include <linux/smp_lock.h>
+ #include <asm/uaccess.h>
+ #include <asm/perf.h>
+ 
+ int do_wait(pid_t pid, unsigned int *stat_addr, int options,
+ 	    struct rusage *ru, unsigned long long *perf_counters);
+ 
+ volatile int              perf_sys_flag=0;
+ static unsigned int       perf_sys_conf   [NR_CPUS][PERF_COUNTERS];
+ static unsigned long long perf_sys_counter[NR_CPUS][PERF_COUNTERS];
+ static unsigned long long perf_sys_shadow_tsc[NR_CPUS];
+ 
+ /*--------------------------------------------------------------------
+  *  System wide counter setup routines.
+  */
+ void perf_sys_remote_sync(void) {
+     int i, id;
+     unsigned long flags;
+     id = smp_processor_id();
+     save_flags(flags);
+     cli();
+     for (i=0; i < PERF_COUNTERS-1; i++) {
+ 	/* Read the value of the performance counter, update the
+ 	 * config, reset the counter to zero. */
+ 	perf_sys_counter[id][i] += (rdmsr(MSR_PERFCTR0+i) & ((1ULL<<40)-1));
+ 	wrmsr(MSR_EVNTSEL0+i, perf_sys_conf[id][i]);
+ 	wrmsr(MSR_PERFCTR0+i, 0);
+     }
+     if (perf_sys_conf[id][2])
+ 	perf_sys_counter[id][2] += perf_get_cycles() - current->perf.shadow_tsc;
+     current->perf.shadow_tsc = perf_get_cycles();
+     restore_flags(flags);
+ }
+ 
+ static
+ void sys_sync_counters(void) {
+ #ifdef __SMP__
+     smp_perf_sys_update();	/* Defined in arch/i386/kernel/smp.c */
+ #else
+     perf_sys_remote_sync();	/* Do it myself too... */
+ #endif
+ }
+ 
+ /*--------------------------------------------------------------------
+  *
+  */
+ static
+ int do_sys_perfop(int op, int arg1, int arg2) {
+     int i, j/*, retval=0 */;
+     int procid, counter;
+ 
+     if (!suser()) 
+ 	return -EPERM;
+ 
+     if ((perf_sys_flag) && (current->perf.options.is_sys_holder == 0))
+ 	return -EBUSY;
+ 
+     switch(op) {
+     case PERF_SYS_START:	/*----------------------------------*/
+ 	for (i=0; i < NR_CPUS; i++) perf_sys_conf[i][0] |= PERF_ENABLE;
+ 	sys_sync_counters();
+ 	return 0;
+     case PERF_SYS_STOP:		/*----------------------------------*/
+ 	for (i=0; i < NR_CPUS; i++) perf_sys_conf[i][0] &= ~PERF_ENABLE;
+ 	sys_sync_counters();
+ 	return 0;
+     case PERF_SYS_READ:		/*----------------------------------*/
+ 	counter = arg1 & 0xff;
+ 	if (counter < 0 || counter >= PERF_COUNTERS) return -EINVAL;
+ 	if (current->perf.options.sum_cpus == 0)
+ 	    {
+ 		procid  = (arg1 >> 8) & 0xff;
+ 		if (procid  < 0 || procid  >= NR_CPUS) return -EINVAL;
+ 		sys_sync_counters();
+ 		return copy_to_user((unsigned long long *) arg2,
+ 				    &perf_sys_counter[procid][counter],
+ 				    sizeof(unsigned long long)) ? -EFAULT : 0;
+ 	    }
+ 	else
+ 	    {
+ 		unsigned long long tmp_tot = 0;
+ 
+ 		sys_sync_counters();
+ 		for (i=0; i < NR_CPUS; i++) 
+ 		    tmp_tot += perf_sys_counter[i][counter];
+ 		return copy_to_user((unsigned long long *) arg2,
+ 				    &tmp_tot,
+ 				    sizeof(unsigned long long)) ? -EFAULT : 0;
+ 	    }
+     case PERF_SYS_RESET:	/*----------------------------------*/
+ 	for (j=0; j < NR_CPUS; j++) 
+ 	    for (i=0; i < PERF_COUNTERS; i++)
+ 		perf_sys_conf   [j][i] = 0;
+ 	sys_sync_counters();
+ 	for (j=0; j < NR_CPUS; j++) 
+ 	    for (i=0; i < PERF_COUNTERS; i++)
+ 		perf_sys_counter[j][i] = 0;
+ 	perf_sys_flag = 0;
+ 	current->perf.options.is_sys_holder = 0;
+ 	return 0;
+     case PERF_SYS_RESET_COUNTERS:	/*----------------------------------*/
+ 	sys_sync_counters();
+ 	for (j=0; j < NR_CPUS; j++) 
+ 	    for (i=0; i < PERF_COUNTERS; i++)
+ 		perf_sys_counter[j][i] = 0;
+ 	return 0;
+     case PERF_SYS_SET_CONFIG:	/*----------------------------------*/
+ 	perf_sys_flag = 1;
+ 	current->perf.options.is_sys_holder = 1;
+ 	procid  = (arg1 >> 8) & 0xff; counter = arg1 & 0xff;
+ 	if (procid  < 0 || procid  >= NR_CPUS ||
+ 	    counter < 0 || counter >= PERF_COUNTERS) return -EINVAL;
+ 	if ((arg2 & (PERF_OS|PERF_USR)) == 0) {
+ 	    arg2 |= PERF_USR;	/* Default mode = PERF_USR */
+ 	}
+ 	perf_sys_conf[procid][counter] =
+ 	  arg2 & (PERF_OS|PERF_USR|PERF_EVNT_MASK|PERF_UNIT_MASK);
+ 	sys_sync_counters();
+ 	return 0;
+     case PERF_SYS_GET_CONFIG:	/*----------------------------------*/
+ 	procid  = (arg1 >> 8) & 0xff;
+ 	counter = arg1 & 0xff;
+ 	if (procid  < 0 || procid  >= NR_CPUS ||
+ 	    counter < 0 || counter >= PERF_COUNTERS) return -EINVAL;
+ 	return put_user(perf_sys_conf[procid][counter] &
+ 			(PERF_OS|PERF_USR|PERF_EVNT_MASK|PERF_UNIT_MASK),
+ 			(int *)arg2);
+     case PERF_SYS_WRITE:	/*----------------------------------*/
+ 	procid  = (arg1 >> 8) & 0xff;
+ 	counter = arg1 & 0xff;
+ 	if (procid  < 0 || procid  >= NR_CPUS ||
+ 	    counter < 0 || counter >= PERF_COUNTERS) return -EINVAL;
+ 	sys_sync_counters();	/* Read the counters before writing in
+ 				 * order zero the hardware counters */
+ 	return copy_from_user(&perf_sys_counter[procid][counter],
+ 			      (unsigned long long *) arg2,
+ 			      sizeof(unsigned long long)) ? -EFAULT : 0;
+     default:
+ 	return -EINVAL;
+     }
+ }
+ 
+ /*--------------------------------------------------------------------
+  * do_user_perfop
+  *
+  *  The CPU counter registers are saved before calling this 
+  *  function and restored afterwards.
+  */
+ static
+ int do_user_perfop(int op, int arg1, int arg2) {
+     switch(op) {
+     case PERF_FASTREAD:
+ 	return copy_to_user((unsigned long long *) arg1,
+ 			    &current->perf.counter[0],
+ 			    PERF_COUNTERS*sizeof(unsigned long long)) 
+ 	    ? -EFAULT: 0;
+     case PERF_FASTWRITE:
+ 	return copy_from_user(&current->perf.counter[0],
+ 			      (unsigned long long *) arg1,
+ 			      PERF_COUNTERS*sizeof(unsigned long long)) 
+ 	    ? -EFAULT: 0;
+     case PERF_FASTCONFIG:	
+ 	return copy_from_user(&current->perf.conf[0], 
+ 			      (unsigned long *) arg1,
+ 			      PERF_COUNTERS*sizeof(int)) 
+ 	    ? -EFAULT: 0;
+     case PERF_RESET_COUNTERS:	/*----------------------------------*/
+ 	{
+ 	    int i;
+ 	    for (i=0; i < PERF_COUNTERS; i++) 
+ 		current->perf.counter[i] = 0;
+ 	    return 0;
+ 	}
+     case PERF_RESET:		/*----------------------------------*/
+ 	{
+ 	    int i;
+ 	    for (i=0; i < PERF_COUNTERS; i++) 
+ 		{
+ 		    current->perf.conf   [i] = 0;
+ 		    current->perf.counter[i] = 0;
+ 		}
+ 	    current->perf.options.do_children = 0;
+ 	    current->perf.options.sum_cpus = 0;
+ 	}
+ 	return 0;
+     case PERF_START:
+ 	current->perf.conf[0] |= PERF_ENABLE;
+ 	return 0;
+     case PERF_STOP:
+ 	current->perf.conf[0] &= ~PERF_ENABLE;
+ 	return 0;
+     case PERF_READ:
+ 	if (arg1 < 0 || arg1 >= PERF_COUNTERS) return -EINVAL;
+ 	return copy_to_user((unsigned long long *) arg2,
+ 			    &current->perf.counter[arg1],
+ 			    sizeof(unsigned long long)) ? -EFAULT: 0;
+     case PERF_SET_OPT:
+ 	{
+ 	    if (arg1 == PERF_DO_CHILDREN)
+ 		current->perf.options.do_children = (arg2 != 0);
+ 	    else if (arg1 == PERF_SUM_CPUS)
+ 		current->perf.options.sum_cpus = (arg2 != 0);
+ 	    else
+ 		return -EINVAL;
+ 	    return 0;
+ 	}
+     case PERF_GET_OPT:
+ 	{
+ 	    int tmp;
+ 
+ 	    if (arg1 == PERF_DO_CHILDREN)
+ 		tmp = (current->perf.options.do_children != 0);
+ 	    else if (arg1 == PERF_SUM_CPUS)
+ 		tmp = (current->perf.options.sum_cpus != 0);
+ 	    else
+ 		return -EINVAL;
+ 
+ 	    return put_user(tmp, (int *) arg2);
+ 	}
+     case PERF_SET_CONFIG:	/*----------------------------------*/
+ 	if (arg1 < 0 || arg1 >= PERF_COUNTERS) return -EINVAL;
+ 	if ((arg2 & (PERF_OS|PERF_USR)) == 0) 
+ 	    arg2 |= PERF_USR;	/* Default mode = PERF_USR */
+ 	current->perf.conf[arg1] =
+ 	    arg2 & (PERF_OS|PERF_USR|PERF_EVNT_MASK|PERF_UNIT_MASK);
+ 	current->perf.counter[arg1] = 0;
+ 	return 0;
+     case PERF_GET_CONFIG:
+ 	if (arg1 < 0 || arg1 >= PERF_COUNTERS) return -EINVAL;
+ 	return put_user(current->perf.conf[arg1] &
+ 			(PERF_OS|PERF_USR|PERF_EVNT_MASK|PERF_UNIT_MASK),
+ 			(int *) arg2);
+     case PERF_WRITE:
+ 	if (arg1 < 0 || arg1 >= PERF_COUNTERS) return -EINVAL;
+ 	return copy_from_user(&current->perf.counter[arg1], 
+ 			      (unsigned long long *) arg2,
+ 			      sizeof(unsigned long long)) ? -EFAULT : 0;
+     case PERF_WAIT:
+ 	{
+ 	    int retval;
+ 	    struct perf_wait_struct p;
+ 	    retval = copy_from_user(&p, (struct perf_wait_struct *)arg1,
+ 			    sizeof(struct perf_wait_struct)) ? -EFAULT : 0;
+ 	    if (retval) return retval;
+ 	    return do_wait(p.pid, p.status, p.options,p.rusage, p.counts);
+ 	}
+     default:
+ 	return -EINVAL;
+     }
+ }
+ 
+ /*
+  * sys_perf
+  *
+  * syscall for manipulation of performance counters.
+  */
+ asmlinkage int
+ sys_perf(int op, int arg1, int arg2) {
+     int retval;
+ 
+     lock_kernel();
+ 
+     switch(op) {
+     case PERF_FASTREAD:
+     case PERF_FASTWRITE:
+     case PERF_FASTCONFIG:
+     case PERF_START:
+     case PERF_STOP:
+     case PERF_RESET:		
+     case PERF_RESET_COUNTERS:  
+     case PERF_SET_CONFIG:
+     case PERF_GET_CONFIG:
+     case PERF_SET_OPT:
+     case PERF_GET_OPT:
+     case PERF_READ:
+     case PERF_WRITE:
+     case PERF_WAIT:
+ 	/* If someone is using the system counters or if our parent has locked our counters, then bail. */
+ 	if ((perf_sys_flag) || (current->perf.options.do_children > 1)) 
+ 	    {
+ 		unlock_kernel();
+ 		return -EBUSY; 
+ 	    }
+ 	perf_save(current->perf.conf, current->perf.counter, &current->perf.shadow_tsc);
+ 	retval = do_user_perfop(op, arg1, arg2);
+ 	perf_restore(current->perf.conf, &current->perf.shadow_tsc);	
+ 	unlock_kernel();
+ 	return retval;
+     case PERF_SYS_RESET:
+     case PERF_SYS_RESET_COUNTERS:
+     case PERF_SYS_SET_CONFIG:
+     case PERF_SYS_GET_CONFIG:
+     case PERF_SYS_START:
+     case PERF_SYS_STOP:
+     case PERF_SYS_READ:
+     case PERF_SYS_WRITE:
+ 	retval = do_sys_perfop(op, arg1, arg2);
+ 	unlock_kernel();
+ 	return retval;
+     case PERF_DEBUG:
+ 	{
+ #define load64(ll,l,h)  (l)=*((int *)&(ll));(h)=*(((int *)&(ll))+1);
+ 	    int hi0, lo0, hi1, lo1, hi2, lo2;
+ 	    printk("-[ %5d ] ------------------------------------\n",
+ 		   current->pid);
+ 	    printk("CONF   :         %08x         %08x          %08x\n",
+ 		   current->perf.conf[0], current->perf.conf[1], 
+ 		   current->perf.conf[2]);
+ 	    load64(current->perf.counter[0], lo0, hi0);
+ 	    load64(current->perf.counter[1], lo1, hi1);
+ 	    load64(current->perf.counter[2], lo2, hi2);
+ 	    printk("COUNTER: %08x%08x %08x%08x %08x%08x\n", 
+ 		   hi0, lo0, hi1, lo1, hi2, lo2);
+ 	    load64(current->perf.shadow_tsc, lo2, hi2);
+ 	    printk("SHADOW_TSC: %08x%08x\n", 
+ 		   hi2, lo2);
+ 	    printk("OPTIONS: do_children %d sum_cpus %d is_sys_holder %d\n",
+ 		   current->perf.options.do_children,
+ 		   current->perf.options.sum_cpus,
+ 		   current->perf.options.is_sys_holder);
+ 	}
+ 	unlock_kernel();
+ 	return 0;
+     default:
+ 	unlock_kernel();
+ 	return -EINVAL;
+     }
+ }
+ 
+ /*
+  * Local variables:
+  * c-basic-offset: 4
+  * End:
+  */
diff -crN linux-2.2.5/arch/i386/kernel/smp.c linux-2.2.5-perf/arch/i386/kernel/smp.c
*** linux-2.2.5/arch/i386/kernel/smp.c	Wed Jun  2 08:36:15 1999
--- linux-2.2.5-perf/arch/i386/kernel/smp.c	Sun Jul 18 19:45:41 1999
***************
*** 39,44 ****
--- 39,47 ----
  #include <linux/smp_lock.h>
  #include <linux/init.h>
  #include <asm/mtrr.h>
+ #ifdef CONFIG_PERF
+ #include <asm/perf.h>
+ #endif
  
  #include "irq.h"
  
***************
*** 121,127 ****
  volatile unsigned long syscall_count=0;			/* Number of times the processor holds the syscall lock	*/
  
  volatile unsigned long ipi_count;			/* Number of IPIs delivered				*/
! 
  const char lk_lockmsg[] = "lock from interrupt context at %p\n"; 
  
  int mp_bus_id_to_type [MAX_MP_BUSSES] = { -1, };
--- 124,132 ----
  volatile unsigned long syscall_count=0;			/* Number of times the processor holds the syscall lock	*/
  
  volatile unsigned long ipi_count;			/* Number of IPIs delivered				*/
! #ifdef CONFIG_PERF
! volatile unsigned long perf_sys_update_needed;
! #endif
  const char lk_lockmsg[] = "lock from interrupt context at %p\n"; 
  
  int mp_bus_id_to_type [MAX_MP_BUSSES] = { -1, };
***************
*** 1666,1671 ****
--- 1671,1721 ----
  {
  	send_IPI_allbutself(MTRR_CHANGE_VECTOR);
  }
+ 
+ #ifdef CONFIG_PERF
+ /* Note this is basically just a copy of smp_flush_tlb (with most of
+  * the comments ripped out for size - see comments there if modifying)
+  * (Doing cli(); while waiting for procs to ACK scares me.  Also,
+  * worrying about "crossing" updates seems unnecessary if holding the
+  * kernel lock is a requirement for calling.  But, hey, I'm not an
+  * expert on this stuff.  I'll follow the example.) */
+ void smp_perf_sys_update(void)
+ {
+ 	int cpu = smp_processor_id();
+ 	int stuck;
+ 	unsigned long flags;
+ 
+ 	if (cpu_online_map) {
+ 		perf_sys_update_needed = cpu_online_map;
+ 
+ 		__save_flags(flags);
+ 		__cli();
+ 
+ 		send_IPI_allbutself(PERF_SYS_UPDATE_VECTOR);
+ 
+ 		stuck = 50000000;
+ 		while (perf_sys_update_needed) {
+ 			if (test_bit(cpu, &perf_sys_update_needed))
+ 			clear_bit(cpu, &perf_sys_update_needed);
+ 			--stuck;
+ 			if (!stuck) {
+ 				printk("stuck on perf update IPI wait (CPU#%d)\n",cpu);
+ 				break;
+ 			}
+ 		}
+ 		__restore_flags(flags);
+ 	}
+ 	perf_sys_remote_sync();
+ }
+ 
+ asmlinkage void smp_perf_sys_update_interrupt(void)
+ {
+ 	if (test_and_clear_bit(smp_processor_id(), &perf_sys_update_needed))
+ 		perf_sys_remote_sync();
+ 
+ 	ack_APIC_irq();
+ }
+ #endif
  
  /*
   * Local timer interrupt handler. It does both profiling and
diff -crN linux-2.2.5/include/asm-i386/perf.h linux-2.2.5-perf/include/asm-i386/perf.h
*** linux-2.2.5/include/asm-i386/perf.h	Wed Dec 31 19:00:00 1969
--- linux-2.2.5-perf/include/asm-i386/perf.h	Wed Jul 21 02:49:44 1999
***************
*** 0 ****
--- 1,235 ----
+ #ifndef _I386_PERF_H_
+ #define _I386_PERF_H_
+ 
+ /* Per process cycle counter is third counter. */
+ #define PERF_CYCLES                 0x1
+ 
+ /* Countable things: (For PPro) */
+ /* Data Cache Unit (DCU) */
+ #define PERF_DATA_MEM_REFS          0x43
+ #define PERF_DCU_LINES_IN           0x45
+ #define PERF_DCU_M_LINES_IN         0x46
+ #define PERF_DCU_M_LINES_OUT        0x47
+ #define PERF_DCU_MISS_STANDING      0x48
+ 
+ /* Instruction Fetch Unit (IFU) */
+ #define PERF_IFU_IFETCH             0x80
+ #define PERF_IFU_IFETCH_MISS        0x81
+ #define PERF_ITLB_MISS              0x85
+ #define PERF_IFU_MEM_STALL          0x86
+ #define PERF_ILD_STALL              0x87
+ 
+ /* L2 Cache */
+ #define PERF_L2_IFETCH              0x28  /* MESI */
+ #define PERF_L2_LD                  0x29  /* MESI */
+ #define PERF_L2_ST                  0x2A  /* MESI */
+ #define PERF_L2_LINES_IN            0x24
+ #define PERF_L2_LINES_OUT           0x26
+ #define PERF_L2_LINES_INM           0x25
+ #define PERF_L2_LINES_OUTM          0x27
+ #define PERF_L2_RQSTS               0x2E  /* MESI */
+ #define PERF_L2_ADS                 0x21
+ #define PERF_L2_DBUS_BUSY           0x22
+ #define PERF_L2_DBUS_BUSY_RD        0x23
+ 
+ /* External Bus Logic */
+ #define PERF_BUS_DRDY_CLOCKS        0x62
+ #define PERF_BUS_LOCK_CLOCKS        0x63
+ #define PERF_BUS_REQ_OUTSTANDING    0x60
+ #define PERF_BUS_TRAN_BRD           0x65
+ #define PERF_BUS_TRAN_RFO           0x66
+ #define PERF_BUS_TRANS_WB           0x67
+ #define PERF_BUS_TRAN_IFETCH        0x68
+ #define PERF_BUS_TRAN_INVAL         0x69
+ #define PERF_BUS_TRAN_PWR           0x6A
+ #define PERF_BUS_TRAN_P             0x6B
+ #define PERF_BUS_TRANS_IO           0x6C
+ #define PERF_BUS_TRAN_DEF           0x6D
+ #define PERF_BUS_TRAN_BURST         0x6E
+ #define PERF_BUS_TRAN_ANY           0x70
+ #define PERF_BUS_TRAN_MEM           0x6F
+ #define PERF_BUS_DATA_RCV           0x64
+ #define PERF_BUS_BNR_DRV            0x61
+ #define PERF_BUS_HIT_DRV            0x7A
+ #define PERF_BUS_HITM_DRV           0x7B
+ #define PERF_BUS_SNOOP_STALL        0x7E
+ 
+ /* Floating point unit */
+ #define PERF_FLOPS                  0xC1
+ #define PERF_FP_COMP_OPS_EXE        0x10
+ #define PERF_FP_ASSIST              0x11
+ #define PERF_MUL                    0x12
+ #define PERF_DIV                    0x13
+ #define PERF_CYCLES_DIV_BUSY        0x14
+ 
+ /* Memory Ordering */
+ #define PERF_LD_BLOCK               0x03
+ #define PERF_SB_DRAINS              0x04
+ #define PERF_MISALIGN_MEM_REF       0x05
+ 
+ /* Instruction Decoding and Retirement */ 
+ #define PERF_INST_RETIRED           0xC0
+ #define PERF_UOPS_RETIRED           0xC2
+ #define PERF_INST_DECODER           0xD0
+ 
+ /* Interrupts */
+ #define PERF_HW_INT_RX              0xC8
+ #define PERF_CYCLES_INST_MASKED     0xC6
+ #define PERF_CYCLES_INT_PENDING_AND_MASKED 0xC7
+ 
+ /* Branches */
+ #define PERF_BR_INST_RETIRED        0xC4
+ #define PERF_BR_MISS_PRED_RETIRED   0xC5
+ #define PERF_BR_TAKEN_RETIRED       0xC9
+ #define PERF_BR_MISS_PRED_TAKEN_RET 0xCA
+ #define PERF_BR_INST_DECODED        0xE0
+ #define PERF_BR_BTB_MISSES          0xE2
+ #define PERF_BR_BOGUS               0xE4
+ #define PERF_BACLEARS               0xE6
+ 
+ /* Stalls */
+ #define PERF_RESOURCE_STALLS        0xA2
+ #define PERF_PARTIAL_RAT_STALLS     0xD2
+ 
+ /* Segment Register Loads */
+ #define PERF_SEGMENT_REG_LOADS      0x06
+ 
+ /* Clocks */
+ #define PERF_CPU_CLK_UNHALTED       0x79
+ 
+ /* Unit mask flags: */
+ #define PERF_SELF                 0x0000
+ #define PERF_ANY                  0x2000
+ #define PERF_CACHE_M              0x0800
+ #define PERF_CACHE_E              0x0400
+ #define PERF_CACHE_S              0x0200
+ #define PERF_CACHE_I              0x0100
+ #define PERF_CACHE_ALL            0x0F00
+ 
+ /*--------------------------------------------------------*/
+ /* Bit masks for configuration fields */
+ #define PERF_CTR_MASK          0xFF000000
+ #define PERF_INV_CTR_MASK      0x00800000
+ #define PERF_ENABLE            0x00400000
+ #define PERF_INT_ENABLE        0x00100000
+ #define PERF_PIN_CONTROL       0x00080000
+ #define PERF_EDGE_DETECT       0x00040000
+ #define PERF_OS                0x00020000
+ #define PERF_USR               0x00010000
+ #define PERF_UNIT_MASK         0x0000FF00
+ #define PERF_EVNT_MASK         0x000000FF
+ 
+ /* System calls */
+ 
+ #define PERF_RESET          0
+ #define PERF_SET_CONFIG     1
+ #define PERF_GET_CONFIG     2
+ #define PERF_START          3
+ #define PERF_STOP           4
+ #define PERF_READ           5
+ #define PERF_WRITE          6
+ #define PERF_WAIT           7
+ #define PERF_DEBUG          8
+ #define PERF_SET_OPT        9
+ #define PERF_GET_OPT        10
+ #define PERF_RESET_COUNTERS 11
+ #define PERF_FASTWRITE      12
+ #define PERF_FASTREAD       13
+ #define PERF_FASTCONFIG     14
+ #define PERF_SYS_RESET      20
+ #define PERF_SYS_SET_CONFIG 21
+ #define PERF_SYS_GET_CONFIG 22
+ #define PERF_SYS_START      23
+ #define PERF_SYS_STOP       24
+ #define PERF_SYS_READ       25
+ #define PERF_SYS_WRITE      26
+ #define PERF_SYS_RESET_COUNTERS 27
+ 
+ /* Options */
+ 
+ #define PERF_DO_CHILDREN    1
+ #define PERF_SUM_CPUS       2
+ 
+ /* Number of performance counters */
+ /* Counter 2 is always the virtual cycle counter. */
+ 
+ #define PERF_COUNTERS 3
+ 
+ struct perf_wait_struct { 
+   pid_t  pid;
+   int   *status;
+   int    options;
+   struct rusage *rusage;
+   unsigned long long *counts;
+ };
+ 
+ #ifdef __KERNEL__
+ 
+ #define MSR_PERFCTR0 0x00C1
+ #define MSR_PERFCTR1 0x00C2
+ #define MSR_EVNTSEL0 0x0186
+ #define MSR_EVNTSEL1 0x0187
+ 
+ struct proc_perf_opt_t {
+     unsigned int do_children:16;
+     unsigned int sum_cpus:8;
+     unsigned int is_sys_holder:8;
+ };
+ 
+ struct proc_perf_t {
+     struct proc_perf_opt_t options;
+     unsigned int       conf   [PERF_COUNTERS];
+     unsigned long long counter[PERF_COUNTERS]; /* Last one is always the TSC for this process */
+     unsigned long long shadow_tsc;
+ };
+ 
+ #define PROC_PERF_INIT {{0,},{0,},{0,},0}
+ 
+ extern volatile int perf_sys_flag;
+ 
+ static inline
+ unsigned long long rdmsr(unsigned int msr) {
+     unsigned long long ret;
+     __asm__ __volatile__("rdmsr"
+ 			 : "=A" (ret)
+ 			 : "c" (msr));
+     return ret;
+ }
+ 
+ static inline
+ void wrmsr(unsigned int msr,unsigned long long val) {
+     __asm__ __volatile__("wrmsr"
+ 			 : /* no Outputs */
+ 			 : "c" (msr), "A" (val));
+ }
+ 
+ static inline unsigned long long perf_get_cycles (void)
+ {
+ 	unsigned long long ret;
+         __asm__ __volatile__("rdtsc"
+ 			    : "=A" (ret)
+ 			    : /* no inputs */);
+         return ret;
+ }
+ 
+ static inline
+ void perf_restore(unsigned int *config, unsigned long long *shadow_tsc) {
+     wrmsr(MSR_EVNTSEL0, config[0]);
+     wrmsr(MSR_PERFCTR0, 0);
+     wrmsr(MSR_EVNTSEL0+1, config[1]);
+     wrmsr(MSR_PERFCTR0+1, 0);
+     *shadow_tsc = perf_get_cycles();
+ }
+ 
+ static inline
+ void perf_save(unsigned int *config, unsigned long long *counter, unsigned long long *shadow_tsc) {
+     counter[0] += (rdmsr(MSR_PERFCTR0)&((1ULL<<40)-1));
+     counter[1] += (rdmsr(MSR_PERFCTR0+1)&((1ULL<<40)-1));
+     if (config[2])
+       counter[2] += perf_get_cycles() - *shadow_tsc;
+ }
+ 
+ void perf_sys_remote_sync(void);
+ void smp_perf_sys_update(void);
+ #endif
+ #endif
diff -crN linux-2.2.5/include/asm-i386/unistd.h linux-2.2.5-perf/include/asm-i386/unistd.h
*** linux-2.2.5/include/asm-i386/unistd.h	Wed Jan 20 14:06:24 1999
--- linux-2.2.5-perf/include/asm-i386/unistd.h	Sun Jul 18 19:45:41 1999
***************
*** 195,200 ****
--- 195,201 ----
  #define __NR_getpmsg		188	/* some people actually want streams */
  #define __NR_putpmsg		189	/* some people actually want streams */
  #define __NR_vfork		190
+ #define __NR_perf		252
  
  /* user-visible error numbers are in the range -1 - -122: see <asm-i386/errno.h> */
  
diff -crN linux-2.2.5/include/linux/sched.h linux-2.2.5-perf/include/linux/sched.h
*** linux-2.2.5/include/linux/sched.h	Wed Jun  2 08:45:53 1999
--- linux-2.2.5-perf/include/linux/sched.h	Sun Jul 18 19:45:41 1999
***************
*** 23,28 ****
--- 23,32 ----
  #include <linux/signal.h>
  #include <linux/securebits.h>
  
+ #ifdef CONFIG_PERF
+ #include <asm/perf.h>
+ #endif
+ 
  /*
   * cloning flags:
   */
***************
*** 328,333 ****
--- 332,341 ----
  	struct signal_queue *sigqueue, **sigqueue_tail;
  	unsigned long sas_ss_sp;
  	size_t sas_ss_size;
+ /* performance monitoring */
+ #ifdef CONFIG_PERF
+ 	struct proc_perf_t perf;
+ #endif
  };
  
  /*
***************
*** 361,366 ****
--- 369,379 ----
   *  INIT_TASK is used to set up the first task table, touch at
   * your own risk!. Base=0, limit=0x1fffff (=2MB)
   */
+ #ifdef CONFIG_PERF
+ #define PERF_INIT PROC_PERF_INIT,
+ #else
+ #define PERF_INIT
+ #endif
  #define INIT_TASK \
  /* state etc */	{ 0,0,0,KERNEL_DS,&default_exec_domain,0, \
  /* counter */	DEF_PRIORITY,DEF_PRIORITY,0, \
***************
*** 394,399 ****
--- 407,413 ----
  /* files */	&init_files, \
  /* mm */	&init_mm, \
  /* signals */	SPIN_LOCK_UNLOCKED, &init_signals, {{0}}, {{0}}, NULL, &init_task.sigqueue, 0, 0, \
+ /* perf */      PERF_INIT \
  }
  
  union task_union {
diff -crN linux-2.2.5/kernel/exit.c linux-2.2.5-perf/kernel/exit.c
*** linux-2.2.5/kernel/exit.c	Wed Jun  2 08:36:14 1999
--- linux-2.2.5-perf/kernel/exit.c	Sun Jul 18 19:45:41 1999
***************
*** 17,22 ****
--- 17,26 ----
  #include <asm/pgtable.h>
  #include <asm/mmu_context.h>
  
+ #ifdef CONFIG_PERF
+ #include <asm/perf.h>
+ #endif
+ 
  extern void sem_exit (void);
  extern struct task_struct *child_reaper;
  
***************
*** 369,374 ****
--- 373,382 ----
  #if CONFIG_AP1000
  	exit_msc(tsk);
  #endif
+ #ifdef CONFIG_PERF
+ 	if (tsk->perf.options.is_sys_holder)
+ 	  perf_sys_flag = 0;
+ #endif
  	__exit_files(tsk);
  	__exit_fs(tsk);
  	__exit_sighand(tsk);
***************
*** 405,411 ****
  	do_exit((error_code&0xff)<<8);
  }
  
! asmlinkage int sys_wait4(pid_t pid,unsigned int * stat_addr, int options, struct rusage * ru)
  {
  	int flag, retval;
  	struct wait_queue wait = { current, NULL };
--- 413,423 ----
  	do_exit((error_code&0xff)<<8);
  }
  
! int do_wait(pid_t pid,unsigned int * stat_addr, int options, struct rusage * ru
! #ifdef CONFIG_PERF
! 	    , unsigned long long *perf_counts
! #endif
! 	    )
  {
  	int flag, retval;
  	struct wait_queue wait = { current, NULL };
***************
*** 443,448 ****
--- 455,471 ----
  				retval = ru ? getrusage(p, RUSAGE_BOTH, ru) : 0; 
  				if (!retval && stat_addr) 
  					retval = put_user((p->exit_code << 8) | 0x7f, stat_addr);
+ #ifdef CONFIG_PERF
+ 				if (p->perf.options.do_children)
+ 				  {
+ 				    current->perf.counter[0] += p->perf.counter[0];
+ 				    current->perf.counter[1] += p->perf.counter[1];
+ 				    current->perf.counter[2] += p->perf.counter[2]; 
+ 				  }
+ 
+ 				if (!retval && perf_counts)
+ 					retval = copy_to_user(perf_counts,p->perf.counter,sizeof(unsigned long long)*PERF_COUNTERS) ? -EFAULT : 0;
+ #endif
  				if (!retval) {
  					p->exit_code = 0;
  					retval = p->pid;
***************
*** 455,460 ****
--- 478,494 ----
  				retval = ru ? getrusage(p, RUSAGE_BOTH, ru) : 0;
  				if (!retval && stat_addr)
  					retval = put_user(p->exit_code, stat_addr);
+ #ifdef CONFIG_PERF
+ 				if (p->perf.options.do_children)
+ 				  {
+ 				    current->perf.counter[0] += p->perf.counter[0];
+ 				    current->perf.counter[1] += p->perf.counter[1];
+ 				    current->perf.counter[2] += p->perf.counter[2]; 
+ 				  }
+ 
+ 				if (!retval && perf_counts)
+ 					retval = copy_to_user(perf_counts,p->perf.counter,sizeof(unsigned long long)*PERF_COUNTERS) ? -EFAULT : 0;
+ #endif
  				if (retval)
  					goto end_wait4; 
  				retval = p->pid;
***************
*** 491,496 ****
--- 525,539 ----
  end_wait4:
  	remove_wait_queue(&current->wait_chldexit,&wait);
  	return retval;
+ }
+ 
+ asmlinkage int sys_wait4(pid_t pid,unsigned int * stat_addr, int options, struct rusage * ru)
+ {
+ 	return do_wait(pid, stat_addr, options, ru
+ #ifdef CONFIG_PERF
+ 		, 0
+ #endif
+ 		);
  }
  
  #ifndef __alpha__
diff -crN linux-2.2.5/kernel/fork.c linux-2.2.5-perf/kernel/fork.c
*** linux-2.2.5/kernel/fork.c	Wed Jun  2 08:36:14 1999
--- linux-2.2.5-perf/kernel/fork.c	Sun Jul 18 19:45:41 1999
***************
*** 22,27 ****
--- 22,31 ----
  #include <asm/mmu_context.h>
  #include <asm/uaccess.h>
  
+ #ifdef CONFIG_PERF
+ #include <asm/perf.h>
+ #endif
+ 
  /* The idle tasks do not count.. */
  int nr_tasks=0;
  int nr_running=0;
***************
*** 644,649 ****
--- 648,683 ----
  #endif
  	p->lock_depth = -1;		/* -1 = no lock */
  	p->start_time = jiffies;
+ #ifdef CONFIG_PERF
+ 	{
+ 		int i;
+ 
+ 		if (current->perf.options.do_children)
+ 		  {
+ 		    p->perf.options    = current->perf.options;
+ 		    p->perf.shadow_tsc = 0;
+ 		    if (current->perf.options.do_children == 1)
+ 		      p->perf.options.do_children = 2;
+ 		    for (i=0; i < PERF_COUNTERS; i++) 
+ 		      {
+ 			p->perf.conf[i]    = current->perf.conf[i];
+ 			p->perf.counter[i] = 0;
+ 		      }
+ 		  }
+ 		else
+ 		  {
+ 		    p->perf.options.do_children = 0;
+ 		    p->perf.options.is_sys_holder = 0;
+ 		    p->perf.options.sum_cpus = 0;
+ 		    p->perf.shadow_tsc = 0;
+ 		    for (i=0; i < PERF_COUNTERS; i++) 
+ 		      {
+ 			p->perf.conf[i]    = 0;
+ 			p->perf.counter[i] = 0;
+ 		      }
+ 		  }
+ 	}
+ #endif
  
  	retval = -ENOMEM;
  	/* copy all the process information */
diff -crN linux-2.2.5/kernel/sched.c linux-2.2.5-perf/kernel/sched.c
*** linux-2.2.5/kernel/sched.c	Mon Mar 15 19:11:55 1999
--- linux-2.2.5-perf/kernel/sched.c	Wed Jul 21 02:54:08 1999
***************
*** 37,43 ****
  #include <asm/pgtable.h>
  #include <asm/mmu_context.h>
  #include <asm/semaphore-helper.h>
! 
  #include <linux/timex.h>
  
  /*
--- 37,45 ----
  #include <asm/pgtable.h>
  #include <asm/mmu_context.h>
  #include <asm/semaphore-helper.h>
! #ifdef CONFIG_PERF
! #include <asm/perf.h>
! #endif
  #include <linux/timex.h>
  
  /*
***************
*** 772,777 ****
--- 774,791 ----
  		sched_data->prev = prev;
  #endif
  	 	kstat.context_swtch++;
+ #ifdef CONFIG_PERF
+ 		{
+ 			unsigned long flags;
+ 			save_flags(flags);
+ 			cli();
+ 			if (!perf_sys_flag) {
+ 				perf_save(prev->perf.conf, prev->perf.counter, &(prev->perf.shadow_tsc));
+ 				perf_restore(next->perf.conf, &(next->perf.shadow_tsc));
+ 			}
+ 			restore_flags(flags);
+ 		}
+ #endif
  		get_mmu_context(next);
  		switch_to(prev,next);
  
